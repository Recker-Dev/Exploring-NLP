{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Preocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bought phone amazon using samsung m30s couple ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awesome book reasonable price must buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book fine bad contains nice concepts nicely ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_text  Rating\n",
       "0                                              liked       1\n",
       "1  bought phone amazon using samsung m30s couple ...       1\n",
       "2             awesome book reasonable price must buy       1\n",
       "3                                               good       1\n",
       "4  book fine bad contains nice concepts nicely ex...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset\\processed_reviews.csv\")\n",
    "df.dropna(subset=[\"Review_text\"], inplace=True) ## Dealing with empty rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizer\n",
    "\n",
    "The WordNet Lemmatizer in NLTK reduces words to their base or dictionary form, called a lemma. Unlike stemming, it uses the WordNet lexical database to ensure valid words.\n",
    "\n",
    "## Usage\n",
    "- Converts inflected forms (e.g., running → run, better → good).\n",
    "- Requires a WordNet installation (`nltk.download('wordnet')`).\n",
    "\n",
    "This is often used in text preprocessing for NLP tasks to normalize words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmatizer\n",
    "import nltk\n",
    "from nltk.stem import  WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Function taking a sentance and lemmatizing the words in it\n",
    "def lemmatize_words(text):\n",
    "    return \"\".join([lemmatizer.lemmatize(word) for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Lemmatizer\n",
    "df[\"Review_text\"] = df[\"Review_text\"].apply(lambda x: lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bought phone amazon using samsung m30s couple ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awesome book reasonable price must buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book fine bad contains nice concepts nicely ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_text  Rating\n",
       "0                                              liked       1\n",
       "1  bought phone amazon using samsung m30s couple ...       1\n",
       "2             awesome book reasonable price must buy       1\n",
       "3                                               good       1\n",
       "4  book fine bad contains nice concepts nicely ex...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(df[\"Review_text\"], df[\"Rating\"],test_size=0.20 , random_state=42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-Of-Words(BOW) and Term Frequency - Inverse Document Frequency(TFIDF) Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization and Naive Bayes Classification\n",
    "\n",
    "This code demonstrates how to preprocess text data using Bag of Words (BoW) and TF-IDF, and apply a Naive Bayes classifier for text classification.\n",
    "\n",
    "## Process Overview\n",
    "\n",
    "### Bag of Words (BoW) Representation\n",
    "- `CountVectorizer` converts text data into a BoW representation.\n",
    "- This creates a sparse matrix where each row corresponds to a document, and each column represents the count of a specific word.\n",
    "\n",
    "### TF-IDF Representation\n",
    "- `TfidfVectorizer` transforms text into TF-IDF features.\n",
    "- It accounts for word frequency within a document and across all documents to assign importance to words.\n",
    "\n",
    "### Naive Bayes Classifier\n",
    "- A `GaussianNB` model is trained using the generated BoW and TF-IDF features.\n",
    "- BoW and TF-IDF features are separately used to build classifiers.\n",
    "- Memory errors are mitigated by reducing data size before training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "\n",
    "bow = CountVectorizer() # Initialize CountVectorizer for Bag-of-Words (BoW) representation\n",
    "X_train_bow = bow.fit_transform(X_train).toarray() # Fit the BoW model to the training data and transform it into an array\n",
    "X_test_bow = bow.transform(X_test).toarray() # Transform the test data using the BoW model into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer() # Initialize TfidfVectorizer for TF-IDF representation\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray() # Fit the TF-IDF model to the training data and transform it into an array\n",
    "X_test_tfidf = tfidf.transform(X_test).toarray() # Transform the test data using the TF-IDF model into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB ## Reduced Size cuz of memory errors\n",
    "\n",
    "# Train a Gaussian Naive Bayes model on a subset of the Bag-of-Words data (to avoid memory issues)\n",
    "nb_model_bow = GaussianNB().fit(X_train_bow[:30000],y_train[:30000])\n",
    "# Train a Gaussian Naive Bayes model on a subset of the TF-IDF data (to avoid memory issues)\n",
    "nb_model_tfidf = GaussianNB().fit(X_train_tfidf[:30000], y_train[:30000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow = nb_model_bow.predict(X_test_bow)\n",
    "y_pred_tfidf = nb_model_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW accuracy:  0.33863655098507955\n",
      "TFIDF accuracy:  0.34836369631522546\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW accuracy: \", accuracy_score(y_test, y_pred_bow))\n",
    "print(\"TFIDF accuracy: \", accuracy_score(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "with open('artifacts/models/nb_model_bow.pkl', 'wb') as file:\n",
    "    pickle.dump(nb_model_bow, file)\n",
    "\n",
    "with open('artifacts/models/nb_model_tfidf.pkl', 'wb') as file:\n",
    "    pickle.dump(nb_model_tfidf, file)\n",
    "\n",
    "\n",
    "# Save the vectorizer \n",
    "with open('artifacts/vectorizer/bow_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(bow, file)\n",
    "\n",
    "with open('artifacts/vectorizer/tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tfidf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
